{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages being downloaded\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import *\n",
    "from tkinter import simpledialog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%python\n",
    "def getFile():\n",
    "    root = Tk()\n",
    "    root.filename =  filedialog.askopenfilename(initialdir = \"/\",title = \"Select file\",filetypes = ((\"text files\",\"*.csv\"),(\"all files\",\"*.*\")))\n",
    "    root.destroy()\n",
    "    return(root.filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(csvName):\n",
    "    df = pd.read_csv(csvName)\n",
    "    print(\"reading csv done\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def userInput():\n",
    "    root = Tk()\n",
    "    root.withdraw()\n",
    "\n",
    "    user_inp = simpledialog.askstring(title=\"SynGlyphX\", \n",
    "        prompt=\"How many columns would you like to include in your visualization?\")\n",
    "    user_int = int(user_inp)\n",
    "    print(\"Use\", user_int, \"columns\")\n",
    "    return user_int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use 12 columns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userInput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def userInput2():\n",
    "    root = Tk()\n",
    "    root.withdraw()\n",
    "\n",
    "    user_inp = simpledialog.askstring(title=\"SynGlyphX\", \n",
    "        prompt=\"How many columns would you like to include in your visualization?\")\n",
    "    user_int = int(user_inp)\n",
    "    print(\"Use\", user_int, \"columns\")\n",
    "    return user_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def typeDefiner(df):\n",
    "    colList = df.columns\n",
    "    colList\n",
    "    x = 0\n",
    "    colNames = []\n",
    "    for name in colList:\n",
    "        if df.dtypes[x] == 'object':# or df.dtypes[x] == 'int64':\n",
    "            pass\n",
    "        else:\n",
    "            colNames.append(colList[x])\n",
    "        x = x + 1\n",
    "    print(\"objects removed\")\n",
    "    print(colNames)\n",
    "    return colNames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def toNumeric():\n",
    "\n",
    "    import xml.etree.ElementTree as ET\n",
    "    #CLEARS COLOR OUT NOW WE CAN INSERT ANYTHING\n",
    "    file = ET.parse('New DAL 900.sdt')\n",
    "    root = file.getroot()\n",
    "    for elem in root.findall('.//Color/RGB/Function[@type=\"Text Field To Value\"]/KeyValuePairs'):\n",
    "        elem.clear()\n",
    "\n",
    "    for parent in root.findall('.//KeyValuePairs/..'):\n",
    "        for element in parent.findall('KeyValuePairs'):\n",
    "            parent.remove(element)\n",
    "   #Try to write here\n",
    "    for elem in root.findall('.//Color/RGB'):\n",
    "        check_req_elems = elem.find('.//Function[@type=\"Text Field To Value\"]')\n",
    "        check_req_elems.type = \"Linear Interpolation\"\n",
    "        check_req_elems.set(\"type\",\"Linear Interpolation\")\n",
    "        attrib = {'type': 'BoundField'}\n",
    "        minmax = ET.SubElement(check_req_elems, 'MinMax', attrib)\n",
    "        minmax.text= \"\\n\\t\\t\\t\\t\\t\\t\\t\"\n",
    "        min = ET.SubElement(minmax, 'Min')\n",
    "        min.text = '0'\n",
    "        min.tail=\"\\n\\t\\t\\t\\t\\t\\t\"\n",
    "        minmax.tail=\"\\n\\t\\t\\t\\t\\t\"\n",
    "    file.write('b.sdt',encoding=\"utf-8\", xml_declaration=True)\n",
    "    print(\"color fixed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XMLParser(colNames, sdtFile):\n",
    "    print(colNames)\n",
    "    tree = ET.parse(sdtFile)\n",
    "    root = tree.getroot()\n",
    "    count=0;\n",
    "    print(len(colNames))\n",
    "    for elem in root.iter('InputField'):\n",
    "        print(count)\n",
    "        #count+=1;\n",
    "        elem.set('field', colNames[count])\n",
    "        count+=1;\n",
    "    #tree.write('New DAL 900.sdt')\n",
    "    tree.write('emptySDT.sdt')\n",
    "    print(\"XML updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runAll(sdtFile):\n",
    "    csv = getFile()\n",
    "    df = readCSV(csv)\n",
    "    colNames = typeDefiner(df)\n",
    "    XMLParser(colNames, sdtFile)\n",
    "   # csv = getFile()\n",
    "#readCSV(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading csv done\n",
      "objects removed\n",
      "['Height', 'Age', 'GPA']\n",
      "['Height', 'Age', 'GPA']\n",
      "3\n",
      "0\n",
      "1\n",
      "2\n",
      "XML updated\n"
     ]
    }
   ],
   "source": [
    "#%%python\n",
    "runAll('emptySDT.sdt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elevationFinder(df):\n",
    "    if df.columns.contains(\"elevation\") or df.columns.contains(\"Elevation\") or df.columns.contains(\"height\"):\n",
    "        longitude = df[\"Longitude\"]\n",
    "    else:\n",
    "        longitude = \"none found\"\n",
    "    return longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latFinder2(df):\n",
    "    x = 0\n",
    "    for columns in df.columns:\n",
    "        searchObj = re.match( r'LAT', df.columns[x], re.I)\n",
    "        if searchObj:\n",
    "            #print(\"found it\")\n",
    "            lat = df.columns[x]\n",
    "            return lat\n",
    "        else:\n",
    "            x = x + 1\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longFinder2(df):\n",
    "    x = 0\n",
    "    for columns in df.columns:\n",
    "        searchObj = re.match( r'LONG', df.columns[x], re.I)\n",
    "        if searchObj:\n",
    "            #print(\"found it\")\n",
    "            long = df.columns[x]\n",
    "            return long\n",
    "        else:\n",
    "            x = x + 1\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
